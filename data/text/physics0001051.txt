Canonical Momenta Indicators of Financial Markets and Neocortical EEG

Lester Ingber

Lester Ingber Research

P.O. Box 857, McLean, Virginia 22101, U.S.A.
ingber@ingber.com, ingber@alumni.caltech.edu

0
0
0
2

 

n
a
J
 

3
2

 
 
 

1
5
0
1
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

Abstract—A  paradigm  of  statistical  mechanics  of  ﬁnancial  markets  (SMFM)  is  ﬁt  to  multivariate  ﬁnancial
markets using Adaptive Simulated Annealing (ASA), a global optimization algorithm, to perform maximum
likelihood ﬁts of Lagrangians deﬁned by path integrals of multivariate conditional probabilities.  Canonical
momenta  are thereby  derived and  used  as  technical  indicators  in  a  recursive  ASA  optimization  process  to
tune  trading  rules. These  trading  rules  are then  used  on  out-of-sample  data,  to  demonstrate  that  they  can
proﬁt from the SMFM model, to illustrate that these markets are likely not efﬁcient. This methodology can
be extended to other systems, e.g., electroencephalography.  This approach to complex systems emphasizes the
utility of blending an intuitive and powerful mathematical-physics formalism to generate indicators which are
used by AI-type rule-based models of management.

1.  Introduction

Over  a  decade  ago,  the  author  published  a  paper  suggesting  the  use  of  newly  developed  methods  of
multivariate nonlinear nonequilibrium calculus to approach a statistical mechanics of ﬁnancial markets (SMFM) [1].
These methods were applied to interest-rate term-structure systems [2,3].  Still, for some time, the standard accepted
paradigm  of  ﬁnancial  markets  has  been  rooted  in  equilibrium  processes [4].  There is  a  current  effort  by  many to
examine nonlinear and nonequilibrium processes in these markets [5], and this paper reinforces this point of view.
Another paper gives some earlier 1991 results using this approach [6].

There are several issues that are clariﬁed here, by presenting calculations of a speciﬁc trading model: (A) It is
demonstrated how multivariate markets might be formulated in a nonequilibrium paradigm. (B) It is demonstrated
that  numerical  methods  of  global  optimization  can  be  used  to  ﬁt  such  SMFM  models  to  data. (C)  A  variational
principle  possessed  by  SMFM  permits  derivation  of  technical  indicators,  such  as  canonical  momenta,  that  can  be
used  to  describe  deviations  from  most  likely  evolving  states  of  the  multivariate  system.
(D)  These  technical
indicators  can  be  embedded  in  realistic  trading  scenarios,  to  test  whether  they can  proﬁt  from  nonequilibrium  in
markets.

Section  2  outlines  the  formalism  used  to  develop  the  nonlinear  nonequilibrium  SMFM  model. Section  3
describes application of SMFM to SP500 cash and future data, using Adaptive Simulated Annealing (ASA) [7] to ﬁt
the  short-time  conditional  probabilities  developed  in  Section  2,  and  to  establish  trading  rules  by  recursively
optimizing with ASA, using optimized technical indicators developed from SMFM. These calculations were brieﬂy
mentioned  in  another  ASA  paper [8].  Section 4 describes  similar  applications,  now in progress,  to  correlating
customized electroencephalographic (EEG) momenta indicators to physiological and behavioral states of humans.
Section 5 is a brief conclusion.

2.  SMFM Model

2.1.  Random walk model

The use of Brownian motion as a model for ﬁnancial systems is generally attributed to Bachelier [9], though
he  incorrectly  intuited  that  the  noise  scaled  linearly  instead  of  as  the  square  root  relative  to the  random  log-price
variable.  Einstein is generally credited with using the correct mathematical description in a larger physical context
of statistical systems. However, sev eral studies imply that changing prices of many markets do not follow a random
walk, that they may have long-term dependences in price correlations, and that they may not be efﬁcient in quickly
arbitraging new information [10-12]. A random walk for returns, rate of change of prices over prices, is described
by  a  Langevin  equation  with  simple  additive  noise h , typically  representing  the  continual  random  inﬂux  of
information into the market.

˙G =  -

g 1 + g 2h ,
/dt ,

˙G = dG
< h (t) >h = 0 , < h (t), h (t¢ ) >h = d (t -

t¢ ) ,

(1)
where g 1 and g 2 are  constants,  and G
is  the  logarithm  of  (scaled)  price. Price,  although  the  most  dramatic
observable, may not be the only appropriate dependent variable or order parameter for the system of markets [13].
This possibility has also been called the “semistrong form of the efﬁcient market hypothesis” [10].
It  is  necessary  to  explore  the  possibilities  that  a  given market  evolves  in  nonequilibrium,  e.g.,  evolving
irreversibly, as well  as  nonlinearly, e.g., g 1,2 may  be  functions  of G
Irreversibility, e.g.,  causality [14]  and
nonlinearity [15], have been suggested as processes necessary to take into account in order to understand markets,
but modern  methods  of  statistical  mechanics  now provide  a  more  explicit  paradigm  to  consistently  include  these
processes in bona ﬁde probability distributions.  Reservations have been expressed about these earlier models at the

.

Canonical momenta indicators of ﬁnancial markets 

- 2 -  

Lester Ingber

time of their presentation [16].

Developments in nonlinear nonequilibrium statistical mechanics in the late 1970’s and their application to a
variety  of  testable  physical  phenomena  illustrate  the  importance  of  properly  treating  nonlinearities  and
nonequilibrium  in  systems  where  simpler  analyses  prototypical  of  linear  equilibrium  Brownian  motion  do  not
sufﬁce [17].

2.2.  Statistical mechanics of large systems

Aggregation  problems  in  nonlinear  nonequilibrium  systems,  e.g.,  as  deﬁnes  a  market  composed  of  many
traders [1], typically  are  “solved”  (accommodated)  by  having  new entities/languages  developed  at  these  disparate
scales in order to efﬁciently pass information back and forth [18,19].  This is quite different from the nature of quasi-
equilibrium quasi-linear systems, where thermodynamic or cybernetic approaches are possible. These approaches
typically fail for nonequilibrium nonlinear systems.

These new methods of nonlinear statistical mechanics only recently have been applied to complex large-scale
physical problems, demonstrating that observed data can be described by the use of these algebraic functional forms.
Success  was  gained  for  large-scale  systems  in  neuroscience,  in  a  series  of  papers  on  statistical  mechanics  of
neocortical interactions [20-30], and in nuclear physics [31-33]. This methodology has been used for problems in
combat  analyses [19,34-37].  These methods  have  been  suggested  for  ﬁnancial  markets [1], applied  to  a  term
structure model of interest rates [2,3], and to optimization of trading [6].

2.3.  Statistical development

When  other  order  parameters  in  addition  to  price  are  included  to  study  markets,  Eq.  (1)  is  accordingly

generalized to a set of Langevin equations.
h j , (G = 1, . . . , L

˙M G = f G + ˆgG
j

) , ( j = 1, . . . , N) ,

˙M G = dM G/dQ
< h j(Q

,

), h j¢ (Q

) >h = 0 , < h j(Q
(2)
j are generally nonlinear functions of mesoscopic order parameters M G, j is a microscopic index
. The  Einstein  convention  of  summing  over repeated  indices  is
is  used  here  to

where f G and ˆgG
indicating  the  source  of  ﬂuctuations,  and N ‡
used.  Vertical  bars  on  an  index,  e.g.,  |j|,  imply  no  sum  is  to  be  taken  on  repeated  indices.
emphasize that the most appropriate time scale for trading may not be real time t.

) >h = d jj¢ d (Q

¢ ) ,

Via a somewhat lengthy,  albeit instructive calculation, outlined in several other papers [1,3,25], involving an
intermediate  derivation  of  a  corresponding  Fokker-Planck  or  Schr¨odinger-type  equation  for  the  conditional
probability distribution P[M(Q
0)], the Langevin rate Eq. (2) is developed into the probability distribution
for M G at  long-time  macroscopic  time  event Q = (u + 1)q + Q
0, in terms  of  a  Stratonovich  path-integral  over
mesoscopic  Gaussian  conditional  probabilities [38-40].  Here, macroscopic  variables  are  deﬁned  as  the  long-time
limit of the evolving mesoscopic system. The corresponding Schr¨odinger-type equation is [39,41]

)|M(Q

¶ P/¶

Q =

1

2

(gGG¢

P),GG¢

(gG P),G + V ,

j ˆgG¢

gGG¢ = kTd jk ˆgG
[. . .],G = ¶ [. . .]/¶ M G .

k

, gG = f G + 1
2

d jk ˆgG¢

j ˆgG
k,G¢

,

(3)
This is properly referred to as a Fokker-Planck equation when V ” 0. Note that although the partial differential Eq.
(3) contains equivalent information regarding M G as in the stochastic differential Eq. (2), all references to j have
been properly averaged over.  I.e., ˆgG
in Eq. (2) is an entity with parameters in both microscopic and mesoscopic
j
spaces, but M is a purely mesoscopic variable, and this is more clearly reﬂected in Eq. (3).

The path integral representation is given in terms of the Lagrangian L.

P[MQ

|MQ 0]dM(Q

) = (cid:242)

. . . (cid:242) DM exp(- S)d [M(Q

0) = M0]d [M(Q

) = MQ ] ,

S = k

- 1
T min

¢ L ,

(cid:242) dQ
Q 0

¢
-
Q
L
Q
-
Q
Canonical momenta indicators of ﬁnancial markets 

- 3 -  

Lester Ingber

DM =

lim
uﬁ

u+1

r =1

g1/2

(2pq

)- 1/2dM G
r

,

G

L( ˙M G, M G, Q

) = 1
2

( ˙M G - hG)gGG¢ ( ˙M G¢

- hG¢ ) + 1
2

hG

;G + R/6 - V ,

hG = gG -

1

2

- 1/2(g1/2gGG¢ ),G¢

g

,

,G + G F

GF hG = g

- 1/2(g1/2hG),G ,

gGG¢ = (gGG¢ )- 1 , g = det(gGG¢ ) ,
;G = hG
hG
JK ” gLF[JK, L] = gLF(gJL,K + gKL,J - gJK,L) ,
G F
R = gJL RJL = gJL gJK RFJKL ,
RFJKL = 1
2

(gFK,JL - gJK,FL - gFL,JK + gJL,FK ) + gMN (G M

FKG N
JL -

G M

FLG N

JK ) .

(4)

Mesoscopic variables have been deﬁned as M G in the Langevin and Fokker-Planck representations, in terms of their
development from the microscopic system labeled by j. The Riemannian curvature term R arises from nonlinear
gGG¢ , which is a bona ﬁde metric of this parameter space [39].
2.4.  Algebraic complexity yields simple intuitive results

It must be emphasized that the output need not be conﬁned to complex algebraic forms or tables of numbers.
Because L possesses a variational principle, sets of contour graphs, at different long-time epochs of the path-integral
of P over its  variables  at  all  intermediate  times,  give  a  visually  intuitive  and  accurate  decision-aid  to  view the
dynamic  evolution  of  the  scenario. For example,  this  Lagrangian  approach  permits  a  quantitative  assessment  of
concepts usually only loosely deﬁned.

“Momentum” = P G =

¶ L
¶ (¶ M G/¶

,

)

“Mass”gGG¢ =

¶ (¶ M G/¶

¶ 2L
)¶ (¶ M G¢ /¶

,

)

“Force” =

¶ L
¶ M G ,

“F = ma ”: d L = 0 =

¶ L
¶ M G

¶ L
¶ (¶ M G/¶

,

)

(5)

where M G are the variables and L is the Lagrangian. These physical entities provide another form of intuitive, but
quantitatively precise, presentation of these analyses. For example, daily newspapers use this terminology to discuss
the movement of security prices. Here, we will use the canonical momenta as indicators to develop trading rules.

2.5.  Fitting parameters

The short-time path-integral Lagrangian of a L

cost function,” C, in terms of parameters, e.g., generically represented as C( ˜a ),

-dimensional system can be developed into a scalar “dynamic

C( ˜a ) = LD

Q +

ln(2p D

) -

2

1

2

ln g ,

(6)

which can be used with the ASA algorithm [7], originally called Very Fast Simulated Reannealing (VFSR) [42], to
ﬁnd the (statistically) best ﬁt of parameters. The cost function for a given system is obtained by the product of P’s
over all data epochs, i.e., a sum of C’s is obtained.  Then, since we essentially are performing a maximum likelihood
ﬁt, the cost functions obtained from somewhat different theories or data can provide a relative statistical measure of
their likelihood, e.g., P12~ exp(C2 - C1).

If there are competing mathematical forms, then it is advantageous to utilize the path-integral to calculate the
long-time evolution of P [19,35].  Experience has demonstrated that the long-time correlations derived from theory,

¥
P
P
Q
Q
Q
-
¶
¶
Q
Q
L
Q
Canonical momenta indicators of ﬁnancial markets 

- 4 -  

Lester Ingber

measured against the observed data, is a viable and expedient way of rejecting models not in accord with observed
evidence.

2.6.  Numerical methodology

ASA [42] ﬁts short-time probability distributions to observed data, using a maximum likelihood technique on
the  Lagrangian. This  algorithm  has  been  developed  to  ﬁt  observed  data  to  a  theoretical  cost  function  over a D-
dimensional parameter space [42], adapting for varying sensitivities of parameters during the ﬁt.

Simulated  annealing  (SA)  was  developed  in  1983  to  deal  with  highly  nonlinear  problems [43],  as  an
extension of a  Monte-Carlo  importance-sampling  technique  developed in 1953 for chemical physics problems. It
helps to visualize the problems presented by such complex systems as a geographical terrain. For example, consider
a mountain range, with two “parameters,” e.g., along the North−South and East−West directions. We  wish to ﬁnd
the lowest valley in this terrain. SA approaches this problem similar to using a bouncing ball that can bounce over
mountains from valley to valley.  We start at a high “temperature,” where the temperature is an SA parameter that
mimics the effect of a fast moving particle in a hot object like a hot molten metal, thereby permitting the ball to
make very high bounces and being able to bounce over any mountain to access any valley,  giv en enough bounces.
As the temperature is made relatively colder, the ball cannot bounce so high, and it also can settle to become trapped
in relatively smaller ranges of valleys.

We  imagine  that  our  mountain  range  is  aptly  described  by  a  “cost  function.” We deﬁne  probability
distributions of the two directional parameters, called generating distributions since they generate possible valleys or
states we are to explore.  We deﬁne another distribution, called the acceptance distribution, which depends on the
difference of cost functions of the present generated valley we are to explore and the last saved lowest valley.  The
acceptance distribution decides probabilistically whether to stay in a new lower valley or to bounce out of it. All the
generating and acceptance distributions depend on temperatures.

In 1984 [44], it was established that SA possessed a proof that, by carefully controlling the rates of cooling of
temperatures, it could statistically ﬁnd the best minimum, e.g., the lowest valley of our example above. This was
good news for people trying to solve hard problems which could not be solved by other algorithms. The bad news
was that the guarantee was only good if they were willing to run SA forever.  In 1987, a method of fast annealing
(FA)  was  developed [45], which  permitted  lowering  the  temperature  exponentially  faster, thereby  statistically
guaranteeing  that  the  minimum  could  be  found  in  some  ﬁnite  time. However,  that  time  still  could  be  quite  long.
Shortly thereafter, in 1987 the author developed Very Fast Simulated Reannealing (VFSR) [42], now called Adaptive
Simulated  Annealing  (ASA),  which  is  exponentially  faster  than  FA.  It
is  used  world-wide  across  many
disciplines [8], and the feedback of many users regularly scrutinizing the source code ensures the soundness of the
code as it becomes more ﬂexible and powerful [46].

ASA  has  been  applied  to  many problems  by  many people  in  many disciplines [8,46,47]. The  code  is
available via anonymous ftp from ftp.ingber.com, which also can be accessed via the world-wide web (WWW) as
http://www.ingber.com/.

3.  Fitting SMFM to SP500

3.1.  Data processing

For the purposes of this paper, it sufﬁces to consider a two-variable problem, SP500 prices of futures, p1, and
cash, p2. (Note  that  in  a  previous  paper [6],  these  two variables  were  inadvertently  incorrectly  reversed.)  Data
included 251 points of 1989 and 252 points of 1990 daily closing data. Time between data was taken as real time t,
e.g., a weekend added two days to the time between data of a Monday and a previous Friday.

It was decided that relative data should be more important to the dynamics of the SMFM model than absolute

data, and an arbitrary form was developed to preprocess data used in the ﬁts,

M i(t) = pi(t + D

t)/ pi(t) ,

where i = {1, 2} = {futures, cash}, and D
trading time. The ratio served to served to suppress strong drifts in the absolute data.

t was the time between neighboring data points, and t + D

3.2.  ASA ﬁts of SMFM to data

Tw o source of noise were assumed, so that the equations of this SMFM model are

(7)
t is the current

(8)

dM G
dt

= 2
G¢= 1
The 8 parameters, { f G

G¢ , ˆgG
i

} were all taken to be constants.

G¢ M G¢ + 2
f G
i=1

h i , G = {1, 2} .

ˆgG
i

As  discussed  previously, the  path-integral  representation  was  used  to  deﬁne  an  effective  cost  function.
Minimization of the cost function was performed using ASA. Some experimentation with the ﬁtting process led to a
scheme whereby after sufﬁcient importance-sampling, the optimization was shunted over to a quasi-local code, the

S
S
Canonical momenta indicators of ﬁnancial markets 

- 5 -  

Lester Ingber

Broyden-Fletcher-Goldfarb-Shanno  (BFGS)  algorithm [48],  to  add  another  decimal  of  precision.
shunted over too quickly to BFGS, then poor ﬁts were obtained, i.e., the ﬁt stopped in a higher local minimum.
G¢ were constrained to lie between -1.0 and 1.0. The parameters ˆgG

Using 1989 data, the parameters f G

constrained  to  lie  between  0  and  1.0. The  values  of  the  parameters,  obtained  by  this  ﬁtting  process  were: f 1
f 2
2 = −0.645172, ˆg2
f 1
2 = −0.068713, ˆg1
0.0686821,
0.00209127, ˆg2
2 = 0.00122221.
3.3.  ASA ﬁts of trading rules

1 = 0.000122309, ˆg1

f 2
1 = 0.645019,

2 = 0.000224755,

i were
1 =
1 =

If  ASA  was

G¢ , ˆgG
i

A simple  model  of  trading  was  developed.  Two  time-weighted  moving  averages,  of  wide  and  narrow
windows, aw and an were deﬁned for each of the two momenta variables.  During each new epoch of aw, always
using  the  ﬁts  of  the  SMFM  model  described  in  the  previous  section  as  a  zeroth  order  estimate,  the  parameters
{ f G
} were  reﬁt  using  data  within  each  epoch. Av eraged  canonical  momenta,  i.e.,  using  Eq.  (5),  were
calculated for each new set of aw and an windows.  Fluctuation parameters D
G
n , were deﬁned, such that
any change in trading position required that there was some reasonable information outside of these ﬂuctuations that
could be used as criteria for trading decisions. No trading was performed for the ﬁrst few days of the year until the
momenta could be calculated. Commissions of $70 were paid every time a new trade of 100 units was taken.  Thus,
there were 6 trading parameters used in this example, {aw, an, D

w and D

n }.

w, D

G

G

G

The  order  of  choices  made  for  daily  trading  are  as  follows.  A 0 represents  no  positions  are  open  and  no
trading  is  performed  until  enough  data  is  gathered,  e.g.,  to  calculate  momenta. A 1 represents  entering  a  long
position, whether from a waiting or a short position, or a current long position was maintained. This was performed
if the both wide-window and narrow-window averaged momenta of both cash and futures prices were both greater
than their D
G
n ﬂuctuation parameters. A −1 represents entering a short position, whether from a waiting
or a long position, or a current short position was maintained. This was performed if the both wide-window and
narrow-window averaged  momenta  of  both  cash  and  futures  prices  were  both  less  than  their D
G
n
ﬂuctuation parameters.

w and D

w and D

G

G

3.4.  In-sample ASA ﬁts of trading rules

For the data of 1989, recursive  optimization was performed. The trading parameters were optimized in an
outer  shell,  using  the  negative  of the  net  yearly  proﬁt/loss  as  a  cost  function. This  could  have  been  weighted  by
something like the absolute value of maximum loss to help minimize risk, but this was not done here. The inner
shell of optimization ﬁne-tuning of the SMFM model was performed daily over the current aw epoch.

At ﬁrst, ASA and shunting over to BFGS was used for each shell, but it was realized that good results could
be obtained using ASA and BFGS on the outer shell, and just BFGS on the inner shell (always using the ASA and
BFGS derived zeroth order SMFM parameters as described above).  Thus, recursive optimization was performed to
establish the required goodness-of-ﬁt, and more efﬁcient local optimization was used only in those instances where
it could replicate the global optimization. This is expected to be quite system dependent.
25, an integers between 3 and 14, D
were: aw = 18, an = 11, D

The trading-rule parameters were constrained to lie within the following ranges: aw integers between 15 and
G
n between 0 and 200. The trading parameters ﬁt by this procedure

w = 30.3474, D

w = 98.0307, D

n = 11.2855, D

2
n = 54.8492.

w and D

G

1

2

1

The summary of results was: cumulative proﬁt = $54170, number of proﬁtable long positions = 11, number of
proﬁtable short positions = 8, number of losing long positions = 5, number of losing short positions = 6, maximum
proﬁt of any giv en trade = $11005, maximum loss of any trade = −$2545, maximum accumulated proﬁt during year
= $54170, maximum loss sustained during year = $0.

3.5.  Out-of-sample SMFM trading

The trading process described above was applied to the 1990 out-of-sample SP500 data. Note that 1990 was
a “bear” market, while 1989 was a “bull” market.  Thus, these two years had quite different overall contexts, and this
was believed to provide a stronger test of this methodology than picking two years with similar contexts.

The inner shell of optimization was performed as described above for 1990 as well. The summary of results
was: cumulative proﬁt = $28300, number of proﬁtable long positions = 10, number of proﬁtable short positions = 6,
number of losing long positions = 6, number of losing short positions = 10, maximum proﬁt of any giv en trade =
$6780, maximum loss of any trade = −$2450, maximum accumulated proﬁt during year = $29965, maximum loss
sustained  during  year  =  −$5945. Tables  of  results  are  available  as  ﬁle  markets96_momenta_tbl.txt.Z  in
http://www.ingber.com/MISC.DIR/ and ftp.ingber.com/MISC.DIR.

Only  one  variable,  the  futures  SP500,  was  actually  traded,  albeit  the  code  can  accommodate  trading  on
multiple  markets.  There is  more  leverage  and  liquidity  in  actually  trading  the  futures  market.  The multivariable
coupling  to  the  cash  market  entered  in  three  important  ways:  (1)  The  SMFM  ﬁts  were  to  the  coupled  system,
requiring a global optimization of all parameters in both markets to deﬁne the time evolution of the futures market.
(2)  The  canonical  momenta  for  the  futures  market  is  in  terms  of  the  partial  derivative  of the  full  Lagrangian;  the
dependency on the cash market enters both as a function of the relative value of the off-diagonal to diagonal terms in

P
P
P
P
P
P
P
P
P
P
P
P
P
P
Canonical momenta indicators of ﬁnancial markets 

- 6 -  

Lester Ingber

the metric, as well as a contribution to the drifts and diffusions from this market.  (3) The canonical momenta of both
markets were used as technical indicators for trading the futures market.

3.6.  Reversing data sets

The same procedures described above were repeated, but using the 1990 SP500 data set for training and the

1989 data set for testing.

For the training phase, using 1990 data, the parameters f G

G¢ were constrained to lie between -1.0 and 1.0. The
i were  constrained  to  lie  between  0  and  1.0. The  values  of  the  parameters,  obtained  by  this  ﬁtting
2 = −0.068571, ˆg1
1 = 0.0685466, f 1
2 =
1 = 9.30768 10- 5, ˆg2
2 = 0.00265532.  Note that these values are quite close to those obtained above

1 = 7.52368 10- 6, ˆg1

2 = 0.000274467, f 2

1 = 0.642585, f 2

The trading-rule parameters were constrained to lie within the following ranges: aw integers between 15 and
G
n between 0 and 200. The trading parameters ﬁt by this procedure

w and D

G

parameters ˆgG
process  were: f 1
−0.642732, ˆg2
when ﬁtting the 1989 data.
25, an integers between 3 and 14, D
were: aw = 11, an = 8, D

1

w = 23.2324, D

2

w = 135.212, D

1

n = 169.512, D

2
n = 9.50857,

The summary of results was: cumulative proﬁt = $42405, number of proﬁtable long positions = 11, number of
proﬁtable short positions = 8, number of losing long positions = 7, number of losing short positions = 6, maximum
proﬁt of any giv en trade = $8280, maximum loss of any trade = −$1895, maximum accumulated proﬁt during year =
$47605, maximum loss sustained during year = −$2915.

For the  testing  phase,  the  summary  of  results  was:  cumulative  proﬁt  =  $35790,  number  of  proﬁtable  long
positions = 10, number of proﬁtable short positions = 6, number of losing long positions = 6, number of losing short
positions  =  3,  maximum  proﬁt  of  any giv en trade  =  $9780,  maximum  loss  of  any trade  =  −$4270,  maximum
accumulated proﬁt during year = $35790, maximum loss sustained during year = $0. Tables of results are available
as ﬁle markets96_momenta_tbl.txt.Z in http://www.ingber.com/MISC.DIR/ and ftp.ingber.com/MISC.DIR.

4.  Extrapolations to EEG

4.1.  Customized Momenta Indicators of EEG

These  techniques  are  quite  generic,  and  can  be  applied  to  a  model  of  statistical  mechanics  of  neocortical
interactions (SMNI) which has utilized similar mathematical and numerical algorithms [20-23,25,26,29,30,49].  In
this approach, the SMNI model is ﬁt to EEG data, e.g., as previously performed [25].  This develops a zeroth order
guess for SMNI parameters for a given subject’s training data. Next, ASA is used recursively to seek parameterized
predictor rules, e.g., modeled according to guidelines used by clinicians. The parameterized predictor rules form an
outer ASA shell, while regularly ﬁne-tuning the SMNI inner-shell parameters within a moving window (one of the
outer-shell  parameters). The  outer-shell  cost  function  is  deﬁned  as  some  measure  of  successful  predictions  of
upcoming EEG events.

In the testing phase, the outer-shell parameters ﬁt in the training phase are used in out-of-sample data. Again,

the process of regularly ﬁne-tuning the inner-shell of SMNI parameters is used in this phase.

If these SMNI techniques can ﬁnd patterns of such such upcoming activity some time before the trained eye
of  the  clinician,  then  the  costs  of  time  and  pain  in  preparation  for  surgery  can  be  reduced. This  project  will
determine inter-electrode and intra-electrode activities prior to spike activity to determine likely electrode circuitries
highly correlated to the onset of seizures. This can only do better than simple averaging or ﬁltering of such activity,
as typically used as input to determine dipole locations of activity prior to the onset of seizures.

If a subset of electrode circuitries are determined to be highly correlated to the onset of seizures, then their
associated  regions  of  activity  can  be  used  as  a  ﬁrst  approximate  of  underlying  dipole  sources  of  brain  activity
affecting seizures. This ﬁrst approximate may be better than using a spherical head model to deduce such a ﬁrst
guess.  Such ﬁrst  approximates  can  then  be  used  for  more  realistic  dipole  source  modeling,  including  the  actual
shape of the brain surface to determine likely localized areas of diseased tissue.

These momenta indicators should be considered as supplemental to other clinical indicators. This is how they

are being used in ﬁnancial trading systems.

5.  Conclusion

A complete  sample  scenario  has  been  presented:  (a)  developing  a  multivariate  nonlinear  nonequilibrium
model  of  ﬁnancial  markets;  (b)  ﬁtting  the  model  to  data  using  methods  of  ASA  global  optimization;  (c)  deriving
technical indicators to express dynamics about most likely states; (d) optimizing trading rules using these technical
indicators;  (e)  trading  on  out-of-sample  data  to  determine  if  steps  (a)−(d)  are  at  least  sufﬁcient  to  proﬁt  by  the
knowledge gained of these ﬁnancial markets, i.e., these markets are not efﬁcient.

Just based the models and representative calculations presented here, no comparisons can yet be made of any
relative  superiority  of  these  techniques  over other  models  of  markets  and  other  sets  of  trading  rules. Rather, this
exercise  should  be  viewed  as  an  explicit  demonstration  (1)  that  ﬁnancial  markets  can  be  modeled  as  nonlinear
nonequilibrium  systems,  and  (2)  that  ﬁnancial  markets  are  not  efﬁcient  and  that  they can  be  properly  ﬁt  and

P
P
P
P
P
P
Canonical momenta indicators of ﬁnancial markets 

- 7 -  

Lester Ingber

proﬁtably traded on real data.

Canonical momenta may offer an intuitive yet detailed coordinate system of some complex systems, which
can be used as reasonable indicators of new and/or strong trends of behavior, upon which reasonable decisions and
actions  can  be  based. A description  has  been  given of a project  in  progress,  using  this  same  methodology  to
customize canonical momenta indicators of EEG to human behavioral and physiological states [50].

References
[1]  L. Ingber, “Statistical mechanics of nonlinear nonequilibrium ﬁnancial markets,” Math. Modelling 5 (6), pp.

343-361, 1984.

[2]  L. Ingber, “Statistical  mechanical  aids  to  calculating  term  structure  models,” Phys.  Rev.  A 42 (12), pp.

7057-7064, 1990.

[3]  L. Ingber, M.F. Wehner, G.M. Jabbour, and T.M. Barnhill, “Application of statistical mechanics methodology

to term-structure bond-pricing models,” Mathl. Comput. Modelling 15 (11), pp. 77-98, 1991.

[4]  R.C. Merton, Continuous-Time Finance, Blackwell, Cambridge, MA, (1992).
[5]  W. Brock,  J.  Lakonishok,  and  B.  LeBaron,  “Simple  technical  trading  rules  and  the  stochastic  properties  of

stock returns,” J. Finance 47 (5), pp. 1731-1763, 1992.

[6]  L. Ingber, “Statistical  mechanics  of  nonlinear  nonequilibrium  ﬁnancial  markets:  Applications  to  optimized

trading,” Mathl. Computer Modelling , pp. (to be published), 1996.

[7]  L.

Ingber, “Adaptive  Simulated  Annealing  (ASA),” [http://www.ingber.com/ASA-shar, ASA-shar.Z,

ASA.tar.Z, ASA.tar.gz, ASA.zip], Lester Ingber Research, McLean, VA, 1993.

[8]  L. Ingber, “Simulated annealing: Practice versus theory,” Mathl. Comput. Modelling 18 (11), pp. 29-57, 1993.
[9]  L. Bachelier, “The´orie de la Spe´culation,” Annales de l’Ecole Normale Supe´rieure 3, 1900.
[10]  M. C.  Jensen,  “Some  anomalous  evidence  regarding  market  efﬁciency,  an editorial  introduction,” J.  Finan.

Econ. 6, pp. 95-101, 1978.

[11]  B. B. Mandelbrot, “When can price be arbitraged efﬁciently? A limit to the validity of the random walk and

martingale models,” Rev. Econ. Statist. 53, pp. 225-236, 1971.

[12]  S. J. Taylor, “Tests of the random walk hypothesis against a price-trend hypothesis,” J.  Finan. Quant. Anal.

17, pp. 37-61, 1982.

[13]  P. Brown, A. W. Kleidon, and T. A. Marsh, “New evidence on the nature of size-related anomalies in stock

prices,” J. Fin. Econ. 12, pp. 33-56, 1983.

[14]  C. W.  J. Granger, “Investigating  causal  relations  by  econometric  models  and  cross-spectral  methods,”

Econometrica 37, pp. 424-438, 1969.

[15]  P. K. Clark,  “A subordinated  stochastic  process  model  with  ﬁnite  variance  for  speculative  prices,”

Econometrica 41, pp. 135-155, 1973.

[16]  B. B.  Mandelbrot,  “Comments  on:  ‘A subordinated  stochastic  process  model  with  ﬁnite  variance  for

speculative prices,’ by Peter K. Clark,” Econometrica 41, pp. 157-159, 1973.

[17]  H. Haken, Synergetics, Springer, New York, (1983).
[18]  L. Ingber, “Mesoscales in neocortex and in command, control and communications (C3) systems,” in Systems
with  Learning  and  Memory  Abilities:  Proceedings,  University  of  Paris  15-19  June  1987, (Edited  by  J.
Delacour and J.C.S. Levy), pp. 387-409, Elsevier, Amsterdam, 1988.

[19]  L. Ingber, “Mathematical comparison of JANUS(T) simulation to National Training Center,” in The Science of
Command  and  Control:  Part  II,  Coping  With  Complexity, (Edited  by  S.E.  Johnson  and  A.H.  Levis),  pp.
165-176, AFCEA International, Washington, DC, 1989.

[20]  L. Ingber, “Statistical mechanics of neocortical interactions. Dynamics of synaptic modiﬁcation,” Phys. Rev. A

28, pp. 395-416, 1983.

[21]  L. Ingber, “Statistical mechanics of neocortical interactions. Derivation of short-term-memory capacity,” Phys.

Rev. A 29, pp. 3346-3358, 1984.

[22]  L. Ingber, “Statistical mechanics of neocortical interactions. EEG dispersion relations,” IEEE Trans. Biomed.

Eng. 32, pp. 91-94, 1985.

[23]  L. Ingber, “Statistical mechanics of neocortical interactions: Stability and duration of the 7– 2 rule of short-

term-memory capacity,” Phys. Rev. A 31, pp. 1183-1186, 1985.

[24]  L.

Ingber  and  P.L.  Nunez,  “Multiple  scales  of  statistical  physics  of  neocortex:  Application 

electroencephalography,” Mathl. Comput. Modelling 13 (7), pp. 83-95, 1990.

[25]  L.

Ingber,

“Statistical  mechanics  of  neocortical 

interactions:  A  scaling  paradigm  applied 

electroencephalography,” Phys. Rev. A 44 (6), pp. 4017-4060, 1991.

to

to

Canonical momenta indicators of ﬁnancial markets 

- 8 -  

Lester Ingber

[26]  L. Ingber, “Generic  mesoscopic  neural  networks  based  on  statistical  mechanics  of  neocortical  interactions,”

Phys. Rev. A 45 (4), pp. R2183-R2186, 1992.

[27]  L. Ingber, “Statistical  mechanics  of  neocortical  interactions:  Path-integral  evolution  of  short-term  memory,”

Phys. Rev. E 49 (5B), pp. 4652-4664, 1994.

[28]  L. Ingber  and  P.L.  Nunez,  “Statistical  mechanics  of  neocortical  interactions:  High  resolution  path-integral

calculation of short-term memory,” Phys. Rev. E 51 (5), pp. 5074-5083, 1995.

[29]  L. Ingber, “Statistical mechanics of multiple scales of neocortical interactions,” in Neocortical Dynamics and

Human EEG Rhythms, (Edited by P.L. Nunez), pp. 628-681, Oxford University Press, New York, NY, 1995.

[30]  L. Ingber, “Statistical mechanics of neocortical interactions: Multiple scales of EEG,” Electroencephal. clin.

Neurophysiol. , pp. (to be published), 1996.

[31]  L.

Ingber, “Riemannian  corrections 

2536-2539, 1983.

to  velocity-dependent  nuclear  forces,” Phys.  Rev.  C 28, pp.

[32]  L. Ingber, “Path-integral  Riemannian  contributions  to  nuclear  Schro¨dinger  equation,” Phys.  Rev.  D 29, pp.

1171-1174, 1984.

[33]  L. Ingber, “Riemannian contributions to short-ranged velocity-dependent nucleon-nucleon interactions,” Phys.

Rev. D 33, pp. 3781-3784, 1986.

[34]  L. Ingber, “Mathematical  comparison  of  computer  models  to  exercise  data,” in 1989  JDL  C2 Symposium:

National Defense University, Washington, DC, 27-29 June 1989, pp. 169-192, SAIC, McLean, VA, 1989.

[35]  L. Ingber, H. Fujio,  and  M.F. Wehner, “Mathematical  comparison  of  combat  computer  models  to  exercise

data,” Mathl. Comput. Modelling 15 (1), pp. 65-90, 1991.

[36]  L. Ingber  and  D.D.  Sworder, “Statistical  mechanics  of  combat  with  human  factors,” Mathl.  Comput.

Modelling 15 (11), pp. 99-127, 1991.

[37]  L. Ingber, “Statistical mechanics of combat and extensions,” in Toward a Science of Command, Control, and
Communications, (Edited  by  C.  Jones),  pp.  117-149,  American  Institute  of  Aeronautics  and  Astronautics,
Washington, D.C., 1993.

[38]  K.S. Cheng,  “Quantization  of  a  general  dynamical  system  by  Feynman’s path  integration  formulation,” J.

Math. Phys. 13, pp. 1723-1726, 1972.

[39]  R. Graham, “Path-integral methods on nonequilibrium thermodynamics and statistics,” in Stochastic Processes
in Nonequilibrium Systems, (Edited by L. Garrido, P. Seglar and P.J. Shepherd), pp. 82-138, Springer, New
York, NY, 1978.

[40]  F. Langouche, D. Roekaerts, and E. Tirapegui, “Short derivation of Feynman Lagrangian for general diffusion

process,” J. Phys. A 113, pp. 449-452, 1980.

[41]  F. Langouche,  D.  Roekaerts,  and  E.  Tirapegui,  “Discretization  problems  of  functional  integrals  in  phase

space,” Phys. Rev. D 20, pp. 419-432, 1979.

[42]  L. Ingber, “Very fast simulated re-annealing,” Mathl. Comput. Modelling 12 (8), pp. 967-973, 1989.
[43]  S. Kirkpatrick,  C.D.  Gelatt,  Jr.,  and  M.P. Vecchi,  “Optimization  by  simulated  annealing,” Science

220 (4598), pp. 671-680, 1983.

[44]  S. Geman and D. Geman, “Stochastic relaxation, Gibbs distribution and the Bayesian restoration in images,”

IEEE Trans. Patt. Anal. Mac. Int. 6 (6), pp. 721-741, 1984.

[45]  H. Szu and R. Hartley, “Fast simulated annealing,” Phys. Lett. A 122 (3-4), pp. 157-162, 1987.
[46]  L. Ingber, “Adaptive simulated annealing (ASA): Lessons learned,” Control and Cybernetics 25 (1), pp. (to be

published), 1996.

[47]  M. Wofsey,  “Technology:  Shortcut  tests  validity  of  complicated  formulas,” The  Wall  Street  Journal

222 (60), pp. B1, 1993.

[48]  D.F. Shanno  and  K.H.  Phua,  “Minimization  of  unconstrained  multivariate  functions,” ACM Trans.  Mathl.

Software 2, pp. 87-94, 1976.

[49]  L. Ingber, “Statistical  mechanics  of  neocortical  interactions.  I.  Basic  formulation,” Physica  D 5, pp.

83-107, 1982.

[50]  L. Ingber, “Canonical  momenta  indicators  of  neocortical  EEG,” in Physics  Computing  96  (PC96), PC96,

Krakow, Poland, 1996.

